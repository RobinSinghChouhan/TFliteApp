{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Add tensorflow libraries"
      ],
      "metadata": {
        "id": "MKyBUCgE6N2T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "ZWltqWQX6J9M"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7RwM0j06YhW",
        "outputId": "304bde7f-df9b-4f0f-f7a3-d95db65227ea"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "xFI8cXi88K2g"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Technology\",\n",
        "        \"Finance\",\n",
        "        \"Design & Arts\",\n",
        "        \"Engineering\",\n",
        "        \"Health & Medicine\",\n",
        "        \"Sports\",\n",
        "        \"Volunteering\",\n",
        "        \"Career Advice\",\n",
        "        \"Startups / Entrepreneurship\",\n",
        "        \"Study\",\n",
        "        \"Internships/Jobs\",\n",
        "        \"Buying/Selling\",\n"
      ],
      "metadata": {
        "id": "3QARawsGPF6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "NELiOTE8ibQU",
        "outputId": "2aa1c2b8-8f5e-4e99-bdeb-3c640d3ba9ee"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-236-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"data\"\n",
        "categories = [\"technology\", \"sports\",\"finance\",\"design_arts\",\"engineering\",\"health_medicine\",\"volunteering\",\"career_advice\",\"entrepreneurship\",\"internships_jobs\",\"study\"]\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for idx, category in enumerate(categories):\n",
        "    csv_path = os.path.join(base_dir, category, f\"{category}_posts_1000.csv\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "    for text in df[\"post\"]:\n",
        "        texts.append(text)\n",
        "        labels.append(idx)  # 0 for technology, 1 for sports\n",
        "\n",
        "print(f\"Loaded {len(texts)} texts with {len(set(labels))} labels\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_SU1CdM7_1k",
        "outputId": "2eca5cde-08b4-4398-eb89-f1c020044c50"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 11000 texts with 11 labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "qDE0q5dr8N29"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Parameters\n",
        "max_features = 10000  # Size of vocabulary\n",
        "sequence_length = 50  # Max number of words per sample\n",
        "\n",
        "# Create the TextVectorization layer\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length\n",
        ")\n",
        "\n",
        "# Adapt the vectorizer to training texts\n",
        "vectorize_layer.adapt(train_texts)\n"
      ],
      "metadata": {
        "id": "hZIt4Jtf8YHc"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert lists to tensors\n",
        "train_texts_ds = tf.data.Dataset.from_tensor_slices((train_texts, train_labels))\n",
        "test_texts_ds = tf.data.Dataset.from_tensor_slices((test_texts, test_labels))\n",
        "\n",
        "# Apply text vectorization\n",
        "def vectorize_text(text, label):\n",
        "    return vectorize_layer(text), label\n",
        "\n",
        "train_ds = train_texts_ds.map(vectorize_text)\n",
        "test_ds = test_texts_ds.map(vectorize_text)\n",
        "\n",
        "# Shuffle, batch, and prefetch\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = train_ds.shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "XPi___cz8tUQ"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(max_features + 1, 16),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),  # Expects 3D input\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(11)  # For 10 classes\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Use pre-vectorized datasets for training\n",
        "history = model.fit(\n",
        "    train_ds,  # already vectorized\n",
        "    validation_data=test_ds,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC-dupVW9Ck6",
        "outputId": "0b1cae16-6360-4205-f73e-8355fee4e2b7"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4833 - loss: 2.3068 - val_accuracy: 0.9786 - val_loss: 1.7893\n",
            "Epoch 2/10\n",
            "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9615 - loss: 1.5420 - val_accuracy: 0.9968 - val_loss: 0.8331\n",
            "Epoch 3/10\n",
            "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9945 - loss: 0.7153 - val_accuracy: 0.9986 - val_loss: 0.3536\n",
            "Epoch 4/10\n",
            "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.3407 - val_accuracy: 0.9995 - val_loss: 0.1739\n",
            "Epoch 5/10\n",
            "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.1915 - val_accuracy: 0.9995 - val_loss: 0.0984\n",
            "Epoch 6/10\n",
            "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9986 - loss: 0.1236 - val_accuracy: 1.0000 - val_loss: 0.0614\n",
            "Epoch 7/10\n",
            "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0877 - val_accuracy: 1.0000 - val_loss: 0.0410\n",
            "Epoch 8/10\n",
            "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0612 - val_accuracy: 1.0000 - val_loss: 0.0288\n",
            "Epoch 9/10\n",
            "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9997 - loss: 0.0502 - val_accuracy: 1.0000 - val_loss: 0.0209\n",
            "Epoch 10/10\n",
            "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9991 - loss: 0.0392 - val_accuracy: 1.0000 - val_loss: 0.0155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export_model = tf.keras.Sequential([\n",
        "    vectorize_layer,\n",
        "    model,\n",
        "    tf.keras.layers.Activation('softmax')  # needed for probabilities\n",
        "])\n"
      ],
      "metadata": {
        "id": "UAnVrJhRAImR"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, losses\n",
        "\n",
        "# Wrap vectorizer + trained model"
      ],
      "metadata": {
        "id": "Gr_lAg0VGLk5"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_model = tf.keras.Sequential([\n",
        "    vectorize_layer,\n",
        "    model,\n",
        "    layers.Activation('softmax')\n",
        "])\n",
        "\n",
        "export_model.compile(\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "zB7jWP9cHJ33"
      },
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_category(text):\n",
        "    input_tensor = tf.constant([text])\n",
        "    probs = export_model.predict(input_tensor)[0]  # softmax output: [prob_tech, prob_sports]\n",
        "\n",
        "    # categories = [\"technology\", \"sports\",\"finance\",\"design_arts\",\"engineering\",]\n",
        "    predicted_index = np.argmax(probs)\n",
        "    predicted_category = categories[predicted_index]\n",
        "\n",
        "    # Format all category probabilities as percentages\n",
        "    prob_percentages = {cat: f\"{prob * 100:.2f}%\" for cat, prob in zip(categories, probs)}\n",
        "\n",
        "    print(f\"Predicted Category: {predicted_category}\")\n",
        "    print(\"Probabilities:\")\n",
        "    for cat, perc in prob_percentages.items():\n",
        "        print(f\" - {cat}: {perc}\")\n"
      ],
      "metadata": {
        "id": "0e0WxAUzHs8p"
      },
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_category(\"Played a great match of cricket with friends in the main ground.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NZFsIhKHuGm",
        "outputId": "f2977511-925a-4283-de8d-e74e7fc3b925"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
            "Predicted Category: sports\n",
            "Probabilities:\n",
            " - technology: 5.94%\n",
            " - sports: 48.68%\n",
            " - finance: 1.96%\n",
            " - design_arts: 3.49%\n",
            " - engineering: 5.95%\n",
            " - health_medicine: 2.20%\n",
            " - volunteering: 8.93%\n",
            " - career_advice: 3.41%\n",
            " - entrepreneurship: 2.62%\n",
            " - internships_jobs: 9.58%\n",
            " - study: 7.25%\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_category(\"Attended event on Budget planning cost saving as a student\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5_tP3vMIQ46",
        "outputId": "2689b1b4-60ff-49bd-ce82-7792fa7b392c"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Predicted Category: finance\n",
            "Probabilities:\n",
            " - technology: 6.33%\n",
            " - sports: 9.29%\n",
            " - finance: 25.45%\n",
            " - design_arts: 4.65%\n",
            " - engineering: 7.38%\n",
            " - health_medicine: 2.94%\n",
            " - volunteering: 5.47%\n",
            " - career_advice: 16.27%\n",
            " - entrepreneurship: 10.27%\n",
            " - internships_jobs: 4.92%\n",
            " - study: 7.04%\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 50], dtype=tf.int32)])\n",
        "def model_wrapper(input):\n",
        "    return model(input)\n",
        "\n",
        "# concrete_func = model_wrapper.get_concrete_function()\n",
        "\n",
        "# converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "# tflite_model = converter.convert()\n",
        "\n",
        "# with open(\"model_fixed.tflite\", \"wb\") as f:\n",
        "#     f.write(tflite_model)"
      ],
      "metadata": {
        "id": "RxwbPD4-BB-e"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the TFlite model for mobile app"
      ],
      "metadata": {
        "id": "-yy6ywi5nObP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob_model = tf.keras.Sequential([\n",
        "    model,  # already trained Dense(10) with logits\n",
        "    tf.keras.layers.Activation('softmax')  # ensures output is probabilities\n",
        "])\n",
        "\n",
        "concrete_func = model_wrapper.get_concrete_function()\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"model_with_softmax.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOg1FhQNAmzB",
        "outputId": "d3b0010f-0f7f-4e5a-8845-9b78913daaf4"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n",
            "WARNING:tensorflow:Issue encountered when serializing table_initializer.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'NoneType' object has no attribute 'name'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xYP-ly4rAofV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=\"model_with_softmax.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "print(\"Input shape:\", input_details[0]['shape'])   # ✅ [1, 50]\n",
        "print(\"Input dtype:\", input_details[0]['dtype'])   # ✅ int32\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF35GRMluMpO",
        "outputId": "b3a118bd-fe10-4305-bab8-edcd5df69e58"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: [ 1 50]\n",
            "Input dtype: <class 'numpy.int32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model_with_softmax.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output index\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_index = input_details[0]['index']\n",
        "output_index = output_details[0]['index']\n",
        "\n",
        "# Vectorize a test sentence using your trained vectorizer\n",
        "sample_text = \"Attended event on Budget planning cost saving as a student\"\n",
        "vec = vectorize_layer(tf.constant([sample_text]))  # shape (1, 50)\n",
        "vec = tf.cast(vec, tf.int32)\n",
        "\n",
        "# Run inference\n",
        "interpreter.set_tensor(input_index, vec.numpy())\n",
        "interpreter.invoke()\n",
        "logits = interpreter.get_tensor(output_index)[0]\n",
        "\n",
        "# Convert logits to probabilities\n",
        "probs = tf.nn.softmax(logits).numpy()\n",
        "\n",
        "# Display\n",
        "for cat, prob in zip(categories, probs):\n",
        "    print(f\"{cat}: {prob * 100:.2f}%\")\n",
        "\n",
        "print(\"Predicted Category:\", categories[np.argmax(probs)])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27d_Rb4q-jVB",
        "outputId": "75fea4b9-2c20-47c8-afb5-b1d425603d4e"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "technology: 6.33%\n",
            "sports: 9.29%\n",
            "finance: 25.45%\n",
            "design_arts: 4.65%\n",
            "engineering: 7.38%\n",
            "health_medicine: 2.94%\n",
            "volunteering: 5.47%\n",
            "career_advice: 16.27%\n",
            "entrepreneurship: 10.27%\n",
            "internships_jobs: 4.92%\n",
            "study: 7.04%\n",
            "Predicted Category: finance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vectorize_layer.get_vocabulary()  # List of tokens in correct order\n"
      ],
      "metadata": {
        "id": "C6QhuRdrXLoX"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"vocab.txt\", \"w\") as f:\n",
        "    for token in vocab:\n",
        "        f.write(token + \"\\n\")\n"
      ],
      "metadata": {
        "id": "_itn4CDMXMz1"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"labels.txt\", \"w\") as f:\n",
        "    for label in categories:\n",
        "        f.write(label + \"\\n\")\n"
      ],
      "metadata": {
        "id": "o6-_nnYJXpgl"
      },
      "execution_count": 316,
      "outputs": []
    }
  ]
}